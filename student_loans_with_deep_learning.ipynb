{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Loan Risk with Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 11:26:18.084666: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Prepare the data to be used on a neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read the `student_loans.csv` file into a Pandas DataFrame. Review the DataFrame, looking for columns that could eventually define your features and target variables.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>payment_history</th>\n",
       "      <th>location_parameter</th>\n",
       "      <th>stem_degree_score</th>\n",
       "      <th>gpa_ranking</th>\n",
       "      <th>alumni_success</th>\n",
       "      <th>study_major_code</th>\n",
       "      <th>time_to_completion</th>\n",
       "      <th>finance_workshop_score</th>\n",
       "      <th>cohort_ranking</th>\n",
       "      <th>total_loan_score</th>\n",
       "      <th>financial_aid_score</th>\n",
       "      <th>credit_ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   payment_history  location_parameter  stem_degree_score  gpa_ranking  \\\n",
       "0              7.4                0.70               0.00          1.9   \n",
       "1              7.8                0.88               0.00          2.6   \n",
       "2              7.8                0.76               0.04          2.3   \n",
       "3             11.2                0.28               0.56          1.9   \n",
       "4              7.4                0.70               0.00          1.9   \n",
       "\n",
       "   alumni_success  study_major_code  time_to_completion  \\\n",
       "0           0.076              11.0                34.0   \n",
       "1           0.098              25.0                67.0   \n",
       "2           0.092              15.0                54.0   \n",
       "3           0.075              17.0                60.0   \n",
       "4           0.076              11.0                34.0   \n",
       "\n",
       "   finance_workshop_score  cohort_ranking  total_loan_score  \\\n",
       "0                  0.9978            3.51              0.56   \n",
       "1                  0.9968            3.20              0.68   \n",
       "2                  0.9970            3.26              0.65   \n",
       "3                  0.9980            3.16              0.58   \n",
       "4                  0.9978            3.51              0.56   \n",
       "\n",
       "   financial_aid_score  credit_ranking  \n",
       "0                  9.4               5  \n",
       "1                  9.8               5  \n",
       "2                  9.8               5  \n",
       "3                  9.8               6  \n",
       "4                  9.4               5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv into a Pandas DataFrame\n",
    "file_path = \"https://static.bc-edx.com/mbc/ai/m6/datasets/student_loans.csv\"\n",
    "\n",
    "\n",
    "# Review the DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "payment_history           float64\n",
       "location_parameter        float64\n",
       "stem_degree_score         float64\n",
       "gpa_ranking               float64\n",
       "alumni_success            float64\n",
       "study_major_code          float64\n",
       "time_to_completion        float64\n",
       "finance_workshop_score    float64\n",
       "cohort_ranking            float64\n",
       "total_loan_score          float64\n",
       "financial_aid_score       float64\n",
       "credit_ranking              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the data types associated with the columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Using the preprocessed data, create the features (`X`) and target (`y`) datasets. The target dataset should be defined by the preprocessed DataFrame column “credit_ranking”. The remaining columns should define the features dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       5\n",
       "1       5\n",
       "2       5\n",
       "3       6\n",
       "4       5\n",
       "       ..\n",
       "1594    5\n",
       "1595    6\n",
       "1596    6\n",
       "1597    5\n",
       "1598    6\n",
       "Name: credit_ranking, Length: 1599, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the target set y using the credit_ranking column\n",
    "y = df[\"credit_ranking\"]\n",
    "\n",
    "# Display a sample of y\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>payment_history</th>\n",
       "      <th>location_parameter</th>\n",
       "      <th>stem_degree_score</th>\n",
       "      <th>gpa_ranking</th>\n",
       "      <th>alumni_success</th>\n",
       "      <th>study_major_code</th>\n",
       "      <th>time_to_completion</th>\n",
       "      <th>finance_workshop_score</th>\n",
       "      <th>cohort_ranking</th>\n",
       "      <th>total_loan_score</th>\n",
       "      <th>financial_aid_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   payment_history  location_parameter  stem_degree_score  gpa_ranking  \\\n",
       "0              7.4                0.70               0.00          1.9   \n",
       "1              7.8                0.88               0.00          2.6   \n",
       "2              7.8                0.76               0.04          2.3   \n",
       "3             11.2                0.28               0.56          1.9   \n",
       "4              7.4                0.70               0.00          1.9   \n",
       "\n",
       "   alumni_success  study_major_code  time_to_completion  \\\n",
       "0           0.076              11.0                34.0   \n",
       "1           0.098              25.0                67.0   \n",
       "2           0.092              15.0                54.0   \n",
       "3           0.075              17.0                60.0   \n",
       "4           0.076              11.0                34.0   \n",
       "\n",
       "   finance_workshop_score  cohort_ranking  total_loan_score  \\\n",
       "0                  0.9978            3.51              0.56   \n",
       "1                  0.9968            3.20              0.68   \n",
       "2                  0.9970            3.26              0.65   \n",
       "3                  0.9980            3.16              0.58   \n",
       "4                  0.9978            3.51              0.56   \n",
       "\n",
       "   financial_aid_score  \n",
       "0                  9.4  \n",
       "1                  9.8  \n",
       "2                  9.8  \n",
       "3                  9.8  \n",
       "4                  9.4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define features set X by selecting all columns but credit_ranking\n",
    "X = df.drop(columns=\"credit_ranking\")\n",
    "\n",
    "# Review the features DataFrame\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Split the features and target sets into training and testing datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the preprocessed data into a training and testing dataset\n",
    "# Assign the function a random_state equal to 1\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Use scikit-learn's `StandardScaler` to scale the features data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_scaler.fit(X_train)\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Compile and Evaluate a Model Using a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create a deep neural network by assigning the number of input features, the number of layers, and the number of neurons on each layer using Tensorflow’s Keras.\n",
    "\n",
    "> **Hint** You can start with a two-layer deep neural network model that uses the `relu` activation function for both layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "# two-deep neural network: input layer, hidden layer 1, hidden layer 2, 1 output layer\n",
    "# there are 11 features and 1 output in the data\n",
    "# inputs and hidden nodes\n",
    "number_inputs = 11\n",
    "\n",
    "# create a sequential neural network\n",
    "# Review the number of features\n",
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of neurons in the output layer\n",
    "number_outputs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of hidden nodes for the first hidden layer\n",
    "hidden_nodes_layer1 = 6\n",
    "\n",
    "\n",
    "# Review the number hidden nodes in the first layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of hidden nodes for the second hidden layer\n",
    "hidden_nodes_layer2 = 3\n",
    "\n",
    "# Review the number hidden nodes in the second layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sequential model instance\n",
    "nn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the first hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer1, input_dim=number_inputs, activation=\"relu\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the second hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn.add(Dense(units=number_outputs, activation=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 6)                 72        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 21        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 97 (388.00 Byte)\n",
      "Trainable params: 97 (388.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display the Sequential model summary\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Compile and fit the model using the `mse` loss function, the `adam` optimizer, and the `mse` evaluation metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 1s 1ms/step - loss: 32.3707 - mse: 32.3707\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 30.0995 - mse: 30.0995\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 27.9759 - mse: 27.9759\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 25.6705 - mse: 25.6705\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 23.1237 - mse: 23.1237\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 20.4715 - mse: 20.4715\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 17.9056 - mse: 17.9056\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 15.6983 - mse: 15.6983\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 13.8785 - mse: 13.8785\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 12.3759 - mse: 12.3759\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 11.0744 - mse: 11.0744\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 9.8750 - mse: 9.8750\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 8.7319 - mse: 8.7319\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 7.6281 - mse: 7.6281\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 6.5634 - mse: 6.5634\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 5.5560 - mse: 5.5560\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 4.6465 - mse: 4.6465\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 3.8494 - mse: 3.8494\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 3.2103 - mse: 3.2103\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.7219 - mse: 2.7219\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.3510 - mse: 2.3510\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.0935 - mse: 2.0935\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.9044 - mse: 1.9044\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.7598 - mse: 1.7598\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.6429 - mse: 1.6429\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.5439 - mse: 1.5439\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.4620 - mse: 1.4620\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.3870 - mse: 1.3870\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.3233 - mse: 1.3233\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.2630 - mse: 1.2630\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.2075 - mse: 1.2075\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.1586 - mse: 1.1586\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.1119 - mse: 1.1119\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.0700 - mse: 1.0700\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.0294 - mse: 1.0294\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.9935 - mse: 0.9935\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.9592 - mse: 0.9592\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.9266 - mse: 0.9266\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.8974 - mse: 0.8974\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.8701 - mse: 0.8701\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.8439 - mse: 0.8439\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.8191 - mse: 0.8191\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.7959 - mse: 0.7959\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.7764 - mse: 0.7764\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.7556 - mse: 0.7556\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.7376 - mse: 0.7376\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.7186 - mse: 0.7186\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6991 - mse: 0.6991\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6826 - mse: 0.6826\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6680 - mse: 0.6680\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6524 - mse: 0.6524\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6386 - mse: 0.6386\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6265 - mse: 0.6265\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6147 - mse: 0.6147\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6044 - mse: 0.6044\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5956 - mse: 0.5956\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5837 - mse: 0.5837\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5734 - mse: 0.5734\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5666 - mse: 0.5666\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5568 - mse: 0.5568\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5480 - mse: 0.5480\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5403 - mse: 0.5403\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5363 - mse: 0.5363\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5283 - mse: 0.5283\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5212 - mse: 0.5212\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5147 - mse: 0.5147\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5098 - mse: 0.5098\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 992us/step - loss: 0.5030 - mse: 0.5030\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4999 - mse: 0.4999\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4937 - mse: 0.4937\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4898 - mse: 0.4898\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4861 - mse: 0.4861\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4817 - mse: 0.4817\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4764 - mse: 0.4764\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4733 - mse: 0.4733\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4699 - mse: 0.4699\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4663 - mse: 0.4663\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4656 - mse: 0.4656\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4610 - mse: 0.4610\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4585 - mse: 0.4585\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4569 - mse: 0.4569\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4556 - mse: 0.4556\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4537 - mse: 0.4537\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4513 - mse: 0.4513\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4475 - mse: 0.4475\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4466 - mse: 0.4466\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4461 - mse: 0.4461\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4426 - mse: 0.4426\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4422 - mse: 0.4422\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4394 - mse: 0.4394\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4377 - mse: 0.4377\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4380 - mse: 0.4380\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4354 - mse: 0.4354\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4342 - mse: 0.4342\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4326 - mse: 0.4326\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4311 - mse: 0.4311\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4313 - mse: 0.4313\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4298 - mse: 0.4298\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4299 - mse: 0.4299\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4276 - mse: 0.4276\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using 100 epochs and the training data\n",
    "student_loan_model = nn.fit(X_train_scaled, y_train, epochs=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate the model using the test data to determine the model’s loss and accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 - 0s - loss: 0.3966 - mse: 0.3966 - 133ms/epoch - 10ms/step\n",
      "Loss: 0.39663153886795044, Accuracy: 0.39663153886795044\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Save and export your model to an HDF5 file, and name the file `student_loans.h5`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rstanbaugh/.pyenv/versions/3.10.2/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Set the model's file path\n",
    "file_path = Path(\"saved_models/student_loans.h5\")\n",
    "\n",
    "\n",
    "# Export your model to a HDF5 file\n",
    "nn.save(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Predict Loan Repayment Success by Using your Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Reload your saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model's file path\n",
    "file_path = Path(\"./saved_models/student_loans.h5\")\n",
    "\n",
    "\n",
    "# Load the model to a new object\n",
    "nn_imported = tf.keras.models.load_model(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Make predictions on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 904us/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the testing data\n",
    "predictions = (nn_imported.predict(X_test_scaled)).round().astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [5],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [5],\n",
       "       [6],\n",
       "       [5]], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 5, 6, 6, 6, 6, 6, 5, 6, 5, 6, 5, 5, 7, 6, 5, 6, 6, 6, 6, 6, 6,\n",
       "       5, 7, 5, 6, 6, 5, 5, 6, 6, 6, 5, 6, 5, 6, 5, 5, 6, 5, 6, 5, 5, 6,\n",
       "       5, 6, 5, 5, 5, 6, 5, 5, 6, 5, 5, 6, 6, 6, 6, 5, 6, 5, 5, 5, 5, 6,\n",
       "       7, 6, 6, 6, 5, 6, 5, 6, 5, 5, 6, 5, 6, 6, 6, 5, 5, 5, 6, 5, 5, 6,\n",
       "       5, 6, 5, 6, 5, 6, 6, 5, 6, 5, 4, 6, 6, 5, 5, 5, 5, 5, 6, 6, 6, 6,\n",
       "       7, 6, 6, 6, 5, 7, 5, 5, 5, 5, 5, 7, 6, 4, 5, 6, 6, 5, 6, 6, 6, 5,\n",
       "       6, 5, 5, 6, 5, 7, 5, 6, 5, 6, 5, 5, 6, 6, 6, 5, 6, 6, 6, 7, 5, 5,\n",
       "       6, 6, 7, 6, 6, 6, 6, 6, 5, 5, 7, 6, 6, 5, 5, 6, 5, 6, 5, 5, 7, 6,\n",
       "       5, 5, 6, 5, 6, 7, 6, 5, 6, 8, 6, 5, 5, 5, 6, 6, 6, 6, 6, 5, 6, 5,\n",
       "       5, 5, 6, 6, 7, 5, 7, 6, 5, 5, 6, 6, 5, 6, 5, 6, 5, 5, 5, 5, 6, 5,\n",
       "       6, 5, 5, 5, 6, 6, 5, 6, 7, 6, 5, 5, 6, 6, 5, 5, 6, 5, 6, 5, 6, 6,\n",
       "       6, 5, 6, 6, 6, 5, 5, 5, 5, 5, 6, 6, 6, 5, 5, 5, 5, 6, 6, 5, 6, 6,\n",
       "       5, 6, 6, 5, 5, 6, 5, 6, 5, 6, 5, 5, 5, 6, 5, 5, 7, 6, 5, 5, 5, 6,\n",
       "       6, 5, 5, 6, 5, 6, 6, 6, 6, 6, 5, 6, 5, 6, 6, 6, 5, 6, 6, 6, 5, 6,\n",
       "       6, 5, 5, 6, 5, 6, 6, 6, 6, 5, 6, 6, 5, 6, 7, 5, 5, 5, 5, 7, 6, 6,\n",
       "       6, 5, 5, 6, 6, 5, 6, 6, 5, 5, 5, 5, 6, 6, 5, 7, 6, 5, 5, 5, 6, 6,\n",
       "       5, 7, 5, 5, 7, 7, 5, 4, 5, 6, 5, 7, 5, 5, 6, 5, 6, 5, 6, 5, 6, 5,\n",
       "       6, 6, 7, 7, 5, 6, 6, 6, 6, 6, 5, 6, 5, 6, 6, 6, 5, 6, 5, 6, 5, 6,\n",
       "       5, 6, 5, 6], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create a DataFrame to compare the predictions with the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to compare the predictions with the actual values\n",
    "results = pd.DataFrame({\"predictions\": predictions.ravel(), \"actual\": y_test})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Display a sample of the DataFrame you created in step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      predictions  actual\n",
       "75              6       5\n",
       "1283            5       6\n",
       "408             6       6\n",
       "1281            6       6\n",
       "1118            6       6\n",
       "1143            6       6\n",
       "1215            6       6\n",
       "181             5       5\n",
       "1186            6       5\n",
       "1252            5       5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display sample data\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of curiosity, wondering if an addiational hidden layer would improve the model\n",
    "\n",
    "number_inputs = 11\n",
    "hidden_nodes_layer1 = 9\n",
    "hidden_nodes_layer2 = 6\n",
    "hidden_nodes_layer3 = 3\n",
    "\n",
    "nn_2 = Sequential()\n",
    "\n",
    "nn_2.add(Dense(units=hidden_nodes_layer1, input_dim=number_inputs, activation=\"relu\"))\n",
    "nn_2.add(Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "nn_2.add(Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "nn_2.add(Dense(units=1, activation=\"linear\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 6)                 60        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 21        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 193 (772.00 Byte)\n",
      "Trainable params: 193 (772.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 1s 1ms/step - loss: 25.1269 - mse: 25.1269\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 19.4253 - mse: 19.4253\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 12.0970 - mse: 12.0970\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 6.2234 - mse: 6.2234\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 4.1371 - mse: 4.1371\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 3.3334 - mse: 3.3334\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.8569 - mse: 2.8569\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.5532 - mse: 2.5532\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.3358 - mse: 2.3358\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.1564 - mse: 2.1564\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.0070 - mse: 2.0070\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.8676 - mse: 1.8676\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.7359 - mse: 1.7359\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.6029 - mse: 1.6029\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.4798 - mse: 1.4798\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.3536 - mse: 1.3536\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.2417 - mse: 1.2417\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.1443 - mse: 1.1443\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.0596 - mse: 1.0596\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.9835 - mse: 0.9835\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.9194 - mse: 0.9194\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.8620 - mse: 0.8620\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.8073 - mse: 0.8073\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.7634 - mse: 0.7634\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.7253 - mse: 0.7253\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6870 - mse: 0.6870\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6578 - mse: 0.6578\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6322 - mse: 0.6322\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6115 - mse: 0.6115\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5920 - mse: 0.5920\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5755 - mse: 0.5755\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5549 - mse: 0.5549\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5422 - mse: 0.5422\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5268 - mse: 0.5268\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5177 - mse: 0.5177\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5081 - mse: 0.5081\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5019 - mse: 0.5019\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4917 - mse: 0.4917\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4828 - mse: 0.4828\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4793 - mse: 0.4793\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4728 - mse: 0.4728\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4670 - mse: 0.4670\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4628 - mse: 0.4628\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4584 - mse: 0.4584\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4539 - mse: 0.4539\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4491 - mse: 0.4491\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4473 - mse: 0.4473\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4464 - mse: 0.4464\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4424 - mse: 0.4424\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4380 - mse: 0.4380\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4355 - mse: 0.4355\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4342 - mse: 0.4342\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4297 - mse: 0.4297\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4288 - mse: 0.4288\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4255 - mse: 0.4255\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4248 - mse: 0.4248\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4220 - mse: 0.4220\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4208 - mse: 0.4208\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4175 - mse: 0.4175\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4169 - mse: 0.4169\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4172 - mse: 0.4172\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4133 - mse: 0.4133\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4115 - mse: 0.4115\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4102 - mse: 0.4102\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4098 - mse: 0.4098\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4089 - mse: 0.4089\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4050 - mse: 0.4050\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4055 - mse: 0.4055\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4026 - mse: 0.4026\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4035 - mse: 0.4035\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4004 - mse: 0.4004\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4035 - mse: 0.4035\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4008 - mse: 0.4008\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3992 - mse: 0.3992\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3983 - mse: 0.3983\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3977 - mse: 0.3977\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3967 - mse: 0.3967\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3950 - mse: 0.3950\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3949 - mse: 0.3949\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3957 - mse: 0.3957\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3973 - mse: 0.3973\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3913 - mse: 0.3913\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3906 - mse: 0.3906\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3915 - mse: 0.3915\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3882 - mse: 0.3882\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3885 - mse: 0.3885\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3892 - mse: 0.3892\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3917 - mse: 0.3917\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3906 - mse: 0.3906\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3875 - mse: 0.3875\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3898 - mse: 0.3898\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3880 - mse: 0.3880\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3859 - mse: 0.3859\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3847 - mse: 0.3847\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3890 - mse: 0.3890\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3862 - mse: 0.3862\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3858 - mse: 0.3858\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3850 - mse: 0.3850\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3829 - mse: 0.3829\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3837 - mse: 0.3837\n"
     ]
    }
   ],
   "source": [
    "nn_2.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "student_loan_model_2 = nn_2.fit(X_train_scaled, y_train, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 - 0s - loss: 0.3966 - mse: 0.3966 - 58ms/epoch - 4ms/step\n",
      "Loss_1: 0.39663153886795044, Accuracy_1: 0.39663153886795044\n",
      "13/13 - 0s - loss: 0.4075 - mse: 0.4075 - 141ms/epoch - 11ms/step\n",
      "Loss_2: 0.40747082233428955, Accuracy_2: 0.40747082233428955\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss_1: {model_loss}, Accuracy_1: {model_accuracy}\")\n",
    "\n",
    "model_loss, model_accuracy = nn_2.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss_2: {model_loss}, Accuracy_2: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08823927017405025"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When calculating the risk level, the prediction is rounded to the nearst whole integer\n",
    "# assuming the \n",
    "predictions_raw = (nn_imported.predict(X_test_scaled))\n",
    "# predictions = (nn_imported.predict(X_test_scaled)).round().astype(\"int32\")\n",
    "\n",
    "import numpy as np\n",
    "mse_predictions = np.mean((predictions-predictions_raw)**2)\n",
    "mse_predictions\n",
    "\n",
    "# adding an additional hidden layer resulted in ≈6% reduction in MSE \n",
    "# This is less than the MSE introsuced by rounding\n",
    "# stick to two layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.8782415],\n",
       "       [5.4037166],\n",
       "       [6.1060066],\n",
       "       [5.700898 ],\n",
       "       [6.375184 ],\n",
       "       [5.9687266],\n",
       "       [6.232463 ],\n",
       "       [4.6749005],\n",
       "       [5.5602736],\n",
       "       [5.0213375],\n",
       "       [6.3546042],\n",
       "       [5.3184166],\n",
       "       [5.352652 ],\n",
       "       [6.666741 ],\n",
       "       [5.6693087],\n",
       "       [5.3304296],\n",
       "       [5.9123874],\n",
       "       [5.508565 ],\n",
       "       [5.5105805],\n",
       "       [5.5044193],\n",
       "       [5.873447 ],\n",
       "       [5.7187448],\n",
       "       [5.4088874],\n",
       "       [7.182464 ],\n",
       "       [5.390429 ],\n",
       "       [6.2532887],\n",
       "       [6.298467 ],\n",
       "       [5.3977194],\n",
       "       [5.41146  ],\n",
       "       [6.342683 ],\n",
       "       [5.6609025],\n",
       "       [6.3738427],\n",
       "       [5.490583 ],\n",
       "       [6.2072377],\n",
       "       [5.1481085],\n",
       "       [5.574974 ],\n",
       "       [5.121603 ],\n",
       "       [5.4579525],\n",
       "       [6.196579 ],\n",
       "       [4.609047 ],\n",
       "       [5.9961243],\n",
       "       [4.775133 ],\n",
       "       [5.0998898],\n",
       "       [6.106289 ],\n",
       "       [5.054347 ],\n",
       "       [5.5962744],\n",
       "       [5.264251 ],\n",
       "       [5.119737 ],\n",
       "       [5.437259 ],\n",
       "       [6.3535247],\n",
       "       [5.358175 ],\n",
       "       [5.2790694],\n",
       "       [6.31209  ],\n",
       "       [4.746109 ],\n",
       "       [5.430372 ],\n",
       "       [5.7952113],\n",
       "       [5.9420905],\n",
       "       [5.803567 ],\n",
       "       [6.022405 ],\n",
       "       [5.0585747],\n",
       "       [5.845489 ],\n",
       "       [5.148625 ],\n",
       "       [5.3334413],\n",
       "       [5.354665 ],\n",
       "       [4.7632246],\n",
       "       [5.573923 ],\n",
       "       [6.5675435],\n",
       "       [5.911915 ],\n",
       "       [6.007924 ],\n",
       "       [6.414014 ],\n",
       "       [5.1481085],\n",
       "       [6.055659 ],\n",
       "       [5.449695 ],\n",
       "       [5.8721313],\n",
       "       [5.122288 ],\n",
       "       [5.2352414],\n",
       "       [5.985345 ],\n",
       "       [5.305475 ],\n",
       "       [5.6202536],\n",
       "       [5.6444063],\n",
       "       [6.213385 ],\n",
       "       [5.1020837],\n",
       "       [5.0215936],\n",
       "       [5.2275133],\n",
       "       [5.7747912],\n",
       "       [5.0799804],\n",
       "       [5.186802 ],\n",
       "       [6.0160933],\n",
       "       [5.46364  ],\n",
       "       [5.7269425],\n",
       "       [5.3457255],\n",
       "       [6.017774 ],\n",
       "       [5.208119 ],\n",
       "       [6.1499133],\n",
       "       [6.3407087],\n",
       "       [5.192186 ],\n",
       "       [6.1345825],\n",
       "       [5.4381404],\n",
       "       [4.2038894],\n",
       "       [6.3437796],\n",
       "       [5.7914457],\n",
       "       [5.375903 ],\n",
       "       [5.3604136],\n",
       "       [5.1640916],\n",
       "       [4.85463  ],\n",
       "       [5.483679 ],\n",
       "       [5.7393613],\n",
       "       [5.743208 ],\n",
       "       [5.7345886],\n",
       "       [6.063466 ],\n",
       "       [6.75662  ],\n",
       "       [5.5921173],\n",
       "       [6.0483856],\n",
       "       [5.5552974],\n",
       "       [4.717917 ],\n",
       "       [6.8729672],\n",
       "       [5.328783 ],\n",
       "       [5.069167 ],\n",
       "       [5.3052063],\n",
       "       [5.38248  ],\n",
       "       [4.692611 ],\n",
       "       [7.101989 ],\n",
       "       [6.26     ],\n",
       "       [4.477868 ],\n",
       "       [5.32057  ],\n",
       "       [5.622903 ],\n",
       "       [5.6397004],\n",
       "       [5.1532784],\n",
       "       [6.3858376],\n",
       "       [5.691847 ],\n",
       "       [5.668841 ],\n",
       "       [5.3556356],\n",
       "       [6.242877 ],\n",
       "       [4.82697  ],\n",
       "       [5.4147153],\n",
       "       [5.987327 ],\n",
       "       [5.0640697],\n",
       "       [7.0566764],\n",
       "       [5.2572603],\n",
       "       [5.5099173],\n",
       "       [4.7982473],\n",
       "       [5.696966 ],\n",
       "       [5.499127 ],\n",
       "       [5.3418136],\n",
       "       [5.793489 ],\n",
       "       [6.0324306],\n",
       "       [5.5672827],\n",
       "       [4.8594785],\n",
       "       [5.6330233],\n",
       "       [6.0245824],\n",
       "       [5.5623713],\n",
       "       [6.504642 ],\n",
       "       [5.3045797],\n",
       "       [5.2597547],\n",
       "       [5.7147307],\n",
       "       [6.109173 ],\n",
       "       [6.656018 ],\n",
       "       [5.861716 ],\n",
       "       [5.99706  ],\n",
       "       [5.5796165],\n",
       "       [6.3900585],\n",
       "       [6.0250793],\n",
       "       [4.9253774],\n",
       "       [5.0397587],\n",
       "       [6.529347 ],\n",
       "       [5.9584928],\n",
       "       [5.615751 ],\n",
       "       [5.1401005],\n",
       "       [5.101384 ],\n",
       "       [5.8520246],\n",
       "       [5.3969216],\n",
       "       [5.921046 ],\n",
       "       [5.0894785],\n",
       "       [5.2152605],\n",
       "       [6.8166394],\n",
       "       [5.5434637],\n",
       "       [5.457457 ],\n",
       "       [5.103889 ],\n",
       "       [5.7617064],\n",
       "       [5.192186 ],\n",
       "       [5.523956 ],\n",
       "       [6.5683017],\n",
       "       [5.887907 ],\n",
       "       [5.337157 ],\n",
       "       [6.1956882],\n",
       "       [7.6128945],\n",
       "       [6.0961637],\n",
       "       [5.4275475],\n",
       "       [4.75083  ],\n",
       "       [5.077965 ],\n",
       "       [5.747112 ],\n",
       "       [5.5723534],\n",
       "       [5.5004015],\n",
       "       [6.0656676],\n",
       "       [5.776391 ],\n",
       "       [5.3475795],\n",
       "       [5.5378585],\n",
       "       [4.997686 ],\n",
       "       [5.4235225],\n",
       "       [5.1985765],\n",
       "       [5.9240985],\n",
       "       [5.588123 ],\n",
       "       [6.573179 ],\n",
       "       [5.21424  ],\n",
       "       [6.658808 ],\n",
       "       [5.684469 ],\n",
       "       [5.258727 ],\n",
       "       [5.0520644],\n",
       "       [5.940633 ],\n",
       "       [5.695397 ],\n",
       "       [5.197703 ],\n",
       "       [6.074084 ],\n",
       "       [5.3604136],\n",
       "       [6.293415 ],\n",
       "       [5.1877503],\n",
       "       [5.1767497],\n",
       "       [5.21882  ],\n",
       "       [5.1357236],\n",
       "       [5.828191 ],\n",
       "       [5.3736024],\n",
       "       [5.5661354],\n",
       "       [5.2277646],\n",
       "       [5.2584386],\n",
       "       [5.4142857],\n",
       "       [5.7981124],\n",
       "       [5.722968 ],\n",
       "       [5.3289633],\n",
       "       [5.567002 ],\n",
       "       [6.6503596],\n",
       "       [5.728003 ],\n",
       "       [4.9536   ],\n",
       "       [5.0488276],\n",
       "       [5.9949555],\n",
       "       [5.9327397],\n",
       "       [4.7633443],\n",
       "       [5.3946605],\n",
       "       [5.8626394],\n",
       "       [5.216757 ],\n",
       "       [5.7687793],\n",
       "       [5.42493  ],\n",
       "       [5.6913686],\n",
       "       [5.677693 ],\n",
       "       [5.7586555],\n",
       "       [5.439872 ],\n",
       "       [5.655089 ],\n",
       "       [6.4408913],\n",
       "       [5.677037 ],\n",
       "       [5.4302416],\n",
       "       [4.926042 ],\n",
       "       [5.243999 ],\n",
       "       [5.1246934],\n",
       "       [4.9668946],\n",
       "       [6.3921995],\n",
       "       [5.6502204],\n",
       "       [6.2555423],\n",
       "       [5.3541365],\n",
       "       [5.0656962],\n",
       "       [4.6093554],\n",
       "       [4.9771934],\n",
       "       [5.936232 ],\n",
       "       [5.66116  ],\n",
       "       [5.4916296],\n",
       "       [5.580858 ],\n",
       "       [5.654709 ],\n",
       "       [5.4261565],\n",
       "       [5.6330233],\n",
       "       [5.612086 ],\n",
       "       [5.058758 ],\n",
       "       [5.170726 ],\n",
       "       [6.0035434],\n",
       "       [5.167355 ],\n",
       "       [5.640735 ],\n",
       "       [5.016769 ],\n",
       "       [6.335954 ],\n",
       "       [5.1577787],\n",
       "       [5.4231076],\n",
       "       [4.753675 ],\n",
       "       [5.921046 ],\n",
       "       [5.462005 ],\n",
       "       [5.401764 ],\n",
       "       [7.4320226],\n",
       "       [5.7161665],\n",
       "       [5.4109845],\n",
       "       [4.9381166],\n",
       "       [5.2186165],\n",
       "       [5.7451735],\n",
       "       [5.5591683],\n",
       "       [5.4996142],\n",
       "       [4.6073947],\n",
       "       [5.6707354],\n",
       "       [5.4238415],\n",
       "       [5.9123874],\n",
       "       [5.8031945],\n",
       "       [5.5941534],\n",
       "       [6.2851057],\n",
       "       [5.8890696],\n",
       "       [5.0628133],\n",
       "       [6.2007804],\n",
       "       [4.9716473],\n",
       "       [5.5213213],\n",
       "       [5.5760894],\n",
       "       [6.280592 ],\n",
       "       [4.969256 ],\n",
       "       [5.69554  ],\n",
       "       [5.5074463],\n",
       "       [5.6031394],\n",
       "       [5.015297 ],\n",
       "       [6.072268 ],\n",
       "       [5.6633534],\n",
       "       [5.074484 ],\n",
       "       [5.421153 ],\n",
       "       [5.58891  ],\n",
       "       [5.488919 ],\n",
       "       [6.2878823],\n",
       "       [5.734551 ],\n",
       "       [5.598231 ],\n",
       "       [5.503244 ],\n",
       "       [4.849886 ],\n",
       "       [6.0138264],\n",
       "       [5.8626394],\n",
       "       [5.367443 ],\n",
       "       [6.047804 ],\n",
       "       [7.075372 ],\n",
       "       [5.1151323],\n",
       "       [5.3475795],\n",
       "       [5.451133 ],\n",
       "       [5.044029 ],\n",
       "       [6.660008 ],\n",
       "       [5.5777054],\n",
       "       [5.613951 ],\n",
       "       [6.1085615],\n",
       "       [4.7448206],\n",
       "       [5.300937 ],\n",
       "       [5.7297697],\n",
       "       [5.6742096],\n",
       "       [5.1355376],\n",
       "       [6.140106 ],\n",
       "       [6.293415 ],\n",
       "       [5.387075 ],\n",
       "       [5.3595147],\n",
       "       [5.3105536],\n",
       "       [5.3391376],\n",
       "       [5.88481  ],\n",
       "       [5.906714 ],\n",
       "       [5.4883447],\n",
       "       [7.261606 ],\n",
       "       [5.958775 ],\n",
       "       [5.1177926],\n",
       "       [5.23421  ],\n",
       "       [5.4443607],\n",
       "       [6.074084 ],\n",
       "       [6.4045887],\n",
       "       [5.398492 ],\n",
       "       [6.5571365],\n",
       "       [5.1655555],\n",
       "       [4.734299 ],\n",
       "       [6.690251 ],\n",
       "       [6.666741 ],\n",
       "       [5.0640697],\n",
       "       [4.4124002],\n",
       "       [4.8369517],\n",
       "       [5.924656 ],\n",
       "       [5.1963663],\n",
       "       [7.154289 ],\n",
       "       [5.471091 ],\n",
       "       [5.1793523],\n",
       "       [5.5299616],\n",
       "       [5.3106585],\n",
       "       [5.801249 ],\n",
       "       [5.3946605],\n",
       "       [5.7486997],\n",
       "       [5.4941783],\n",
       "       [5.5260844],\n",
       "       [5.348064 ],\n",
       "       [5.5870852],\n",
       "       [5.566667 ],\n",
       "       [6.8763375],\n",
       "       [7.0540743],\n",
       "       [5.1767497],\n",
       "       [5.9588304],\n",
       "       [5.8963447],\n",
       "       [5.9359407],\n",
       "       [5.711177 ],\n",
       "       [5.991738 ],\n",
       "       [5.304317 ],\n",
       "       [6.424644 ],\n",
       "       [4.7403746],\n",
       "       [5.8096566],\n",
       "       [5.810285 ],\n",
       "       [5.640483 ],\n",
       "       [5.3554244],\n",
       "       [5.6688576],\n",
       "       [5.3403897],\n",
       "       [5.7161393],\n",
       "       [5.1655426],\n",
       "       [5.7198663],\n",
       "       [5.46364  ],\n",
       "       [5.9949555],\n",
       "       [5.4573107],\n",
       "       [6.328652 ]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_raw"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
